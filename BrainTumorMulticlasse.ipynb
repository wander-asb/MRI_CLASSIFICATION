{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BrainTumorMulticlasse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxX7VHqO13LhrVGeAI9o2U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliotecas"
      ],
      "metadata": {
        "id": "zSwSvBtKULWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHwq95ulwuP8",
        "outputId": "d34432b0-80e4-4fff-fcf0-e961ecd5b24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão: 1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import torch    \n",
        "import os  \n",
        "import numpy                as np\n",
        "import pandas               as pd\n",
        "import torch.nn.functional  as F\n",
        "import matplotlib.pyplot    as plt\n",
        "import seaborn              as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express       as px\n",
        "\n",
        "from PIL                         import Image\n",
        "from torch                       import nn, optim\n",
        "from torch.nn.modules            import padding\n",
        "from torch.nn.modules.activation import ReLU\n",
        "from torchvision                 import datasets, transforms as T\n",
        "from plotly.subplots             import make_subplots\n",
        "from google.colab                import drive\n",
        "\n",
        "print(\"Versão:\",torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07XfyanXw3fp",
        "outputId": "ab01ad94-e9cf-4894-8dc6-dfb5f39abf80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "categorias = ['Glioma','Meningioma','Hipófise','Saudável']\n",
        "\n",
        "transform = T.Compose(\n",
        "    [\n",
        "     T.Resize([128,128]),\n",
        "     T.ToTensor(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "DIWJ_sloxILS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_treino = '/content/gdrive/MyDrive/MRI_TUMOR_CNN/Dataset80_20BrainTumor/Treino'\n",
        "path_teste = '/content/gdrive/MyDrive/MRI_TUMOR_CNN/Dataset80_20BrainTumor/Teste'"
      ],
      "metadata": {
        "id": "9l20gVW_xg-O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_treino = datasets.ImageFolder(path_treino, transform=transform)\n",
        "loader_treino = torch.utils.data.DataLoader(dataset_treino, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "fzM0hbDsyBpE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_teste = datasets.ImageFolder(path_teste, transform=transform)\n",
        "loader_teste = torch.utils.data.DataLoader(dataset_teste, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8TjgtNPDyBOx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def base_de_dados(dataset):\n",
        "  quantidade = {k: 0 for k, v in dataset.class_to_idx.items()}\n",
        "  for i in dataset:\n",
        "    rotulos = i[1]\n",
        "    rotulos = indice_por_classe[rotulos]\n",
        "    quantidade[rotulos] += 1\n",
        "  return quantidade\n",
        "\n",
        "indice_por_classe = {v: k for k, v in dataset_treino.class_to_idx.items()}\n",
        "df_treino = pd.DataFrame.from_dict([base_de_dados(dataset_treino)]).melt()\n",
        "\n",
        "indice_por_classe = {v: k for k, v in dataset_teste.class_to_idx.items()}\n",
        "df_teste = pd.DataFrame.from_dict([base_de_dados(dataset_teste)]).melt()\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
        "\n",
        "fig.add_trace(go.Pie(\n",
        "    labels=df_treino['variable'],\n",
        "     values=df_treino['value'],\n",
        "      pull=[0, 0, 0.1, 0]),\n",
        "       1, 1)\n",
        "\n",
        "fig.add_trace(go.Pie(\n",
        "    labels=df_teste['variable'],\n",
        "     values=df_teste['value'],\n",
        "      pull=[0, 0, 0.1, 0]),\n",
        "       1, 2)\n",
        "\n",
        "fig.update_traces(hole=.4,\n",
        "    hoverinfo='label+percent',\n",
        "                  textinfo='value',\n",
        "                  textfont_size=12.5,\n",
        "                  marker=dict(\n",
        "                      line=dict(\n",
        "                          color='#000000',\n",
        "                           width=1)\n",
        "                      )\n",
        "                  )\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text = 'Proporção da base de dados de treino e teste',\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OyWg59LfoqJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classificador(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convs = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=10),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(num_features=64),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Dropout(p = 0.1),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Dropout(p = 0.2),\n",
        "    )\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(in_features=16384, out_features=256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=256, out_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=128, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=4),\n",
        "    )\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "  def forward(self, X):\n",
        "    convolucoes = self.convs(X)\n",
        "    vetor = self.flatten(convolucoes)\n",
        "    output = self.layers(vetor)\n",
        "    return output"
      ],
      "metadata": {
        "id": "KcPkNmx5y0Sh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = classificador()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CfJDh9eA4FXy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
        "print(device,\"\\n\")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XCVFZMX36fm",
        "outputId": "9fb0501f-77c5-40c9-ea1b-5c142af3b354"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classificador(\n",
              "  (convs): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(10, 10), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.1, inplace=False)\n",
              "    (8): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=16384, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=4, bias=True)\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataLoader, criterion, optimizer):\n",
        "  model.train()\n",
        "  cumloss = 0.0\n",
        "  for imagens, rotulos in dataLoader:\n",
        "\n",
        "    imagens, rotulos = imagens.to(device), rotulos.to(device)\n",
        "\n",
        "    pred = model(imagens)\n",
        "    loss = criterion(pred, rotulos)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cumloss += loss.item()\n",
        "\n",
        "  return cumloss/len(dataLoader)"
      ],
      "metadata": {
        "id": "IuQ69ASE4EcM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(model, dataLoader, lossfunc):\n",
        "    model.eval()\n",
        "    cumloss = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataLoader:\n",
        "            \n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            \n",
        "            pred = model(imgs)\n",
        "            \n",
        "            loss = lossfunc(pred, labels)\n",
        "            \n",
        "            cumloss += loss.item()\n",
        "            \n",
        "    return cumloss / len(dataLoader)"
      ],
      "metadata": {
        "id": "edH_mkX2683A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_treino = []\n",
        "losses_teste = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  loss_treino = train(model, loader_treino, criterion, optimizer)\n",
        "  losses_treino.append(loss_treino)\n",
        "  if (i%10==0):\n",
        "    print(f\"Época: {i}; Loss Treino: {loss_treino}\")\n",
        "\n",
        "  loss_val = validacao(model, loader_teste, criterion)\n",
        "  losses_teste.append(loss_val)"
      ],
      "metadata": {
        "id": "MU_Zly_r7G0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dcc795-a6fb-4234-9ddf-29357b8c8650"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época: 0; Loss Treino: 1.4013210651351184\n",
            "Época: 10; Loss Treino: 1.2518675821583445\n",
            "Época: 20; Loss Treino: 0.7788222141382171\n",
            "Época: 30; Loss Treino: 0.6286451016984335\n",
            "Época: 40; Loss Treino: 0.5403321178221121\n",
            "Época: 50; Loss Treino: 0.47749003677106483\n",
            "Época: 60; Loss Treino: 0.39905126429185633\n",
            "Época: 70; Loss Treino: 0.35014787843314615\n",
            "Época: 80; Loss Treino: 0.29171031077460546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gráficos"
      ],
      "metadata": {
        "id": "hWPdtwszMmxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(losses):\n",
        "  fig = plt.figure(figsize=(13,5))\n",
        "  ax = fig.gca()\n",
        "  for loss_name, loss_values in losses.items():\n",
        "    ax.plot(loss_values, label=loss_name)\n",
        "  ax.legend(fontsize=\"16\")\n",
        "  ax.set_xlabel(\"Epoch\", fontsize=\"16\")\n",
        "  ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
        "  ax.set_title(\"Loss vs epochs\", fontsize=\"16\");\n",
        "\n",
        "def make_confusion_matrix(model, loader, classes):\n",
        "  confusion_matrix = torch.zeros(classes, classes, dtype=torch.int64)\n",
        "  with torch.no_grad():\n",
        "    for i ,(imagens, rotulos) in enumerate(loader):\n",
        "      imagens, rotulos = imagens.to(device), rotulos.to(device) \n",
        "      output = model(imagens)\n",
        "      _, pred = torch.max(output, 1)\n",
        "      for j, k in zip(torch.as_tensor(rotulos, dtype=torch.int64).view(-1),\n",
        "                      torch.as_tensor(pred, dtype=torch.int64).view(-1)):\n",
        "        confusion_matrix[j, k] += 1\n",
        "  return confusion_matrix \n",
        "\n",
        "\n",
        "def evaluate_accuracy(model, loader, classes, verbose=True):\n",
        "\n",
        "  pred_corretos = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "  confusion_matrix = make_confusion_matrix(model, loader, len(classes))\n",
        "\n",
        "  if (verbose):\n",
        "    total_de_correto = 0.0\n",
        "    total_de_preditos = 0.0\n",
        "\n",
        "    for i, classname in enumerate(classes):\n",
        "      correct_count = confusion_matrix[i][i].item()\n",
        "      class_pred = torch.sum(confusion_matrix[i]).item()\n",
        "\n",
        "      total_de_correto += correct_count\n",
        "      total_de_preditos += class_pred\n",
        "\n",
        "      accuracy = 100 * float(correct_count) / class_pred\n",
        "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                    accuracy))\n",
        "  print(\"Global acccuracy is {:.1f}\".format(100 * total_de_correto/total_de_preditos))\n",
        "  return confusion_matrix\n",
        "\n",
        "def test(model, loader, classes):\n",
        "  pred_corretos = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "  with torch.no_grad():\n",
        "    for imagens, rotulos in loader:\n",
        "      imagens, rotulos = imagens.to(device), rotulos.to(device) \n",
        "      output = model(imagens)\n",
        "      _, pred = torch.max(output, 1)\n",
        "      for rotulo, previsoes in zip(rotulos, pred):\n",
        "        if rotulo == previsoes:\n",
        "          pred_corretos[classes[rotulo]] += 1\n",
        "        total_pred[classes[rotulo]] += 1\n",
        "\n",
        "\n",
        "  total_de_correto = 0.0\n",
        "  total_de_preditos = 0.0\n",
        "  for nome_da_classe, qtd_corretos in pred_corretos.items():\n",
        "    total_de_correto += qtd_corretos\n",
        "    total_de_preditos += total_pred[nome_da_classe]\n",
        "    acuracia = 100* float(qtd_corretos) / total_pred[nome_da_classe]\n",
        "    print(\"Acurácia da classe {}: {:.2f}\".format(nome_da_classe, acuracia))\n",
        "  print(\"Acurácia geral: {:.2f}\".format(100*total_de_correto/total_de_preditos))"
      ],
      "metadata": {
        "id": "8VkRRkxZ-t9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualização de indicadores de desempenho"
      ],
      "metadata": {
        "id": "Yl80ngd8ZUN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_de_loss = {'Loss de treino':losses_treino,\n",
        "                  'Loss de teste':losses_teste}\n",
        "plot_loss(grafico_de_loss)"
      ],
      "metadata": {
        "id": "qDZn9XTIMlNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz = evaluate_accuracy(model, loader_teste, categorias)"
      ],
      "metadata": {
        "id": "W5zeOmx_ZKRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(matriz.tolist(), \n",
        "           annot=True, annot_kws={\"size\": 16}, fmt='d')"
      ],
      "metadata": {
        "id": "IHkqAirKZ9nJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}